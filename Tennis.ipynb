{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the Tennis UnityEnvironment with 2 ddpg players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n",
      "N_Bootstrap\n",
      "4\n",
      "seed\n",
      "0\n",
      "prio\n",
      "0.8\n",
      "Episode 0\tAverage Score: 0.0000\n",
      "14\n",
      "0.07244645601511002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oliver/.local/lib/python3.6/site-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 30\tAverage Score: 0.0067\n",
      "477\n",
      "0.03272761031985283\n",
      "Episode 60\tAverage Score: 0.0197\n",
      "1021\n",
      "0.03847460076212883\n",
      "Episode 90\tAverage Score: 0.0283\n",
      "1642\n",
      "0.044690167367458344\n",
      "Episode 120\tAverage Score: 0.0720\n",
      "2648\n",
      "0.0704820528626442\n",
      "Episode 150\tAverage Score: 0.0967\n",
      "3824\n",
      "0.10864820331335068\n",
      "Episode 180\tAverage Score: 0.1217\n",
      "5366\n",
      "0.14947903156280518\n",
      "Episode 210\tAverage Score: 0.3727\n",
      "9926\n",
      "0.3483369052410126\n",
      "\n",
      "Environment solved in 191 episodes!\tAverage Score: 0.52\n",
      "\n",
      "Environment solved in 192 episodes!\tAverage Score: 0.52\n",
      "\n",
      "Environment solved in 193 episodes!\tAverage Score: 0.52\n",
      "\n",
      "Environment solved in 194 episodes!\tAverage Score: 0.53\n",
      "\n",
      "Environment solved in 195 episodes!\tAverage Score: 0.52\n",
      "\n",
      "Environment solved in 196 episodes!\tAverage Score: 0.56\n",
      "\n",
      "Environment solved in 197 episodes!\tAverage Score: 0.58\n",
      "\n",
      "Environment solved in 198 episodes!\tAverage Score: 0.62\n",
      "\n",
      "Environment solved in 199 episodes!\tAverage Score: 0.70\n",
      "\n",
      "Environment solved in 200 episodes!\tAverage Score: 0.67\n",
      "\n",
      "Environment solved in 201 episodes!\tAverage Score: 0.69\n",
      "\n",
      "Environment solved in 202 episodes!\tAverage Score: 0.69\n",
      "\n",
      "Environment solved in 203 episodes!\tAverage Score: 0.68\n",
      "\n",
      "Environment solved in 204 episodes!\tAverage Score: 0.67\n",
      "\n",
      "Environment solved in 205 episodes!\tAverage Score: 0.69\n",
      "\n",
      "Environment solved in 206 episodes!\tAverage Score: 0.68\n",
      "\n",
      "Environment solved in 207 episodes!\tAverage Score: 0.68\n",
      "\n",
      "Environment solved in 208 episodes!\tAverage Score: 0.68\n",
      "\n",
      "Environment solved in 209 episodes!\tAverage Score: 0.65\n",
      "Episode 240\tAverage Score: 0.5790\n",
      "16829\n",
      "3.1315484046936035\n",
      "\n",
      "Environment solved in 210 episodes!\tAverage Score: 0.58\n",
      "\n",
      "Environment solved in 211 episodes!\tAverage Score: 0.58\n",
      "\n",
      "Environment solved in 212 episodes!\tAverage Score: 0.56\n",
      "\n",
      "Environment solved in 213 episodes!\tAverage Score: 0.57\n",
      "\n",
      "Environment solved in 214 episodes!\tAverage Score: 0.61\n",
      "\n",
      "Environment solved in 215 episodes!\tAverage Score: 0.61\n",
      "\n",
      "Environment solved in 216 episodes!\tAverage Score: 0.56\n",
      "\n",
      "Environment solved in 217 episodes!\tAverage Score: 0.57\n",
      "\n",
      "Environment solved in 218 episodes!\tAverage Score: 0.62\n",
      "\n",
      "Environment solved in 219 episodes!\tAverage Score: 0.61\n",
      "\n",
      "Environment solved in 220 episodes!\tAverage Score: 0.59\n",
      "\n",
      "Environment solved in 221 episodes!\tAverage Score: 0.59\n",
      "\n",
      "Environment solved in 222 episodes!\tAverage Score: 0.59\n",
      "\n",
      "Environment solved in 223 episodes!\tAverage Score: 0.59\n",
      "\n",
      "Environment solved in 224 episodes!\tAverage Score: 0.58\n",
      "\n",
      "Environment solved in 225 episodes!\tAverage Score: 0.59\n",
      "\n",
      "Environment solved in 226 episodes!\tAverage Score: 0.56\n",
      "\n",
      "Environment solved in 227 episodes!\tAverage Score: 0.53\n",
      "Episode 270\tAverage Score: 0.4500\n",
      "22341\n",
      "18.46862030029297\n",
      "\n",
      "Environment solved in 255 episodes!\tAverage Score: 0.51\n",
      "\n",
      "Environment solved in 256 episodes!\tAverage Score: 0.53\n",
      "\n",
      "Environment solved in 257 episodes!\tAverage Score: 0.61\n",
      "\n",
      "Environment solved in 258 episodes!\tAverage Score: 0.69\n",
      "\n",
      "Environment solved in 259 episodes!\tAverage Score: 0.77\n",
      "\n",
      "Environment solved in 260 episodes!\tAverage Score: 0.80\n",
      "\n",
      "Environment solved in 261 episodes!\tAverage Score: 0.84\n",
      "\n",
      "Environment solved in 262 episodes!\tAverage Score: 0.92\n",
      "\n",
      "Environment solved in 263 episodes!\tAverage Score: 0.98\n",
      "\n",
      "Environment solved in 264 episodes!\tAverage Score: 1.05\n",
      "\n",
      "Environment solved in 265 episodes!\tAverage Score: 1.08\n",
      "\n",
      "Environment solved in 266 episodes!\tAverage Score: 1.06\n",
      "\n",
      "Environment solved in 267 episodes!\tAverage Score: 1.03\n",
      "\n",
      "Environment solved in 268 episodes!\tAverage Score: 0.98\n",
      "\n",
      "Environment solved in 269 episodes!\tAverage Score: 0.97\n",
      "Episode 300\tAverage Score: 0.9920\n",
      "33915\n",
      "73.59508514404297\n",
      "\n",
      "Environment solved in 270 episodes!\tAverage Score: 0.99\n",
      "\n",
      "Environment solved in 271 episodes!\tAverage Score: 1.05\n",
      "\n",
      "Environment solved in 272 episodes!\tAverage Score: 1.03\n",
      "\n",
      "Environment solved in 273 episodes!\tAverage Score: 1.05\n",
      "\n",
      "Environment solved in 274 episodes!\tAverage Score: 0.99\n",
      "\n",
      "Environment solved in 275 episodes!\tAverage Score: 1.03\n",
      "\n",
      "Environment solved in 276 episodes!\tAverage Score: 1.04\n",
      "\n",
      "Environment solved in 277 episodes!\tAverage Score: 1.04\n",
      "\n",
      "Environment solved in 278 episodes!\tAverage Score: 1.10\n",
      "\n",
      "Environment solved in 279 episodes!\tAverage Score: 1.10\n",
      "\n",
      "Environment solved in 280 episodes!\tAverage Score: 1.18\n",
      "\n",
      "Environment solved in 281 episodes!\tAverage Score: 1.19\n",
      "\n",
      "Environment solved in 282 episodes!\tAverage Score: 1.21\n",
      "\n",
      "Environment solved in 283 episodes!\tAverage Score: 1.24\n",
      "\n",
      "Environment solved in 284 episodes!\tAverage Score: 1.29\n",
      "\n",
      "Environment solved in 285 episodes!\tAverage Score: 1.29\n",
      "\n",
      "Environment solved in 286 episodes!\tAverage Score: 1.28\n",
      "\n",
      "Environment solved in 287 episodes!\tAverage Score: 1.28\n",
      "\n",
      "Environment solved in 288 episodes!\tAverage Score: 1.28\n",
      "\n",
      "Environment solved in 289 episodes!\tAverage Score: 1.20\n",
      "\n",
      "Environment solved in 290 episodes!\tAverage Score: 1.16\n",
      "\n",
      "Environment solved in 291 episodes!\tAverage Score: 1.12\n",
      "\n",
      "Environment solved in 292 episodes!\tAverage Score: 1.12\n",
      "\n",
      "Environment solved in 293 episodes!\tAverage Score: 1.07\n",
      "\n",
      "Environment solved in 294 episodes!\tAverage Score: 0.99\n",
      "\n",
      "Environment solved in 295 episodes!\tAverage Score: 0.99\n",
      "\n",
      "Environment solved in 296 episodes!\tAverage Score: 0.99\n",
      "\n",
      "Environment solved in 297 episodes!\tAverage Score: 1.02\n",
      "\n",
      "Environment solved in 298 episodes!\tAverage Score: 1.02\n",
      "\n",
      "Environment solved in 299 episodes!\tAverage Score: 1.01\n",
      "Episode 330\tAverage Score: 1.0133\n",
      "45819\n",
      "197.96978759765625\n",
      "\n",
      "Environment solved in 300 episodes!\tAverage Score: 1.01\n",
      "\n",
      "Environment solved in 301 episodes!\tAverage Score: 0.95\n",
      "\n",
      "Environment solved in 302 episodes!\tAverage Score: 0.93\n",
      "\n",
      "Environment solved in 303 episodes!\tAverage Score: 0.95\n",
      "\n",
      "Environment solved in 304 episodes!\tAverage Score: 0.96\n",
      "\n",
      "Environment solved in 305 episodes!\tAverage Score: 0.95\n",
      "\n",
      "Environment solved in 306 episodes!\tAverage Score: 0.94\n",
      "\n",
      "Environment solved in 307 episodes!\tAverage Score: 0.97\n",
      "\n",
      "Environment solved in 308 episodes!\tAverage Score: 0.91\n",
      "\n",
      "Environment solved in 309 episodes!\tAverage Score: 0.95\n",
      "\n",
      "Environment solved in 310 episodes!\tAverage Score: 0.88\n",
      "\n",
      "Environment solved in 311 episodes!\tAverage Score: 0.89\n",
      "\n",
      "Environment solved in 312 episodes!\tAverage Score: 0.87\n",
      "\n",
      "Environment solved in 313 episodes!\tAverage Score: 0.85\n",
      "\n",
      "Environment solved in 314 episodes!\tAverage Score: 0.80\n",
      "\n",
      "Environment solved in 315 episodes!\tAverage Score: 0.84\n",
      "\n",
      "Environment solved in 316 episodes!\tAverage Score: 0.90\n",
      "\n",
      "Environment solved in 317 episodes!\tAverage Score: 0.90\n",
      "\n",
      "Environment solved in 318 episodes!\tAverage Score: 0.84\n",
      "\n",
      "Environment solved in 319 episodes!\tAverage Score: 0.93\n",
      "\n",
      "Environment solved in 320 episodes!\tAverage Score: 1.01\n",
      "\n",
      "Environment solved in 321 episodes!\tAverage Score: 1.03\n",
      "\n",
      "Environment solved in 322 episodes!\tAverage Score: 1.02\n",
      "\n",
      "Environment solved in 323 episodes!\tAverage Score: 1.04\n",
      "\n",
      "Environment solved in 324 episodes!\tAverage Score: 1.06\n",
      "\n",
      "Environment solved in 325 episodes!\tAverage Score: 1.12\n",
      "\n",
      "Environment solved in 326 episodes!\tAverage Score: 1.21\n",
      "\n",
      "Environment solved in 327 episodes!\tAverage Score: 1.26\n",
      "\n",
      "Environment solved in 328 episodes!\tAverage Score: 1.32\n",
      "\n",
      "Environment solved in 329 episodes!\tAverage Score: 1.32\n",
      "Episode 360\tAverage Score: 1.2993\n",
      "61045\n",
      "365.49462890625\n",
      "\n",
      "Environment solved in 330 episodes!\tAverage Score: 1.30\n",
      "\n",
      "Environment solved in 331 episodes!\tAverage Score: 1.32\n",
      "\n",
      "Environment solved in 332 episodes!\tAverage Score: 1.39\n",
      "\n",
      "Environment solved in 333 episodes!\tAverage Score: 1.42\n",
      "\n",
      "Environment solved in 334 episodes!\tAverage Score: 1.42\n",
      "\n",
      "Environment solved in 335 episodes!\tAverage Score: 1.47\n",
      "\n",
      "Environment solved in 336 episodes!\tAverage Score: 1.50\n",
      "\n",
      "Environment solved in 337 episodes!\tAverage Score: 1.55\n",
      "\n",
      "Environment solved in 338 episodes!\tAverage Score: 1.58\n",
      "\n",
      "Environment solved in 339 episodes!\tAverage Score: 1.56\n",
      "\n",
      "Environment solved in 340 episodes!\tAverage Score: 1.61\n",
      "\n",
      "Environment solved in 341 episodes!\tAverage Score: 1.67\n",
      "\n",
      "Environment solved in 342 episodes!\tAverage Score: 1.69\n",
      "\n",
      "Environment solved in 343 episodes!\tAverage Score: 1.72\n",
      "\n",
      "Environment solved in 344 episodes!\tAverage Score: 1.70\n",
      "\n",
      "Environment solved in 345 episodes!\tAverage Score: 1.62\n",
      "\n",
      "Environment solved in 346 episodes!\tAverage Score: 1.55\n",
      "\n",
      "Environment solved in 347 episodes!\tAverage Score: 1.55\n",
      "\n",
      "Environment solved in 348 episodes!\tAverage Score: 1.53\n",
      "\n",
      "Environment solved in 349 episodes!\tAverage Score: 1.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Environment solved in 350 episodes!\tAverage Score: 1.44\n",
      "\n",
      "Environment solved in 351 episodes!\tAverage Score: 1.50\n",
      "\n",
      "Environment solved in 352 episodes!\tAverage Score: 1.46\n",
      "\n",
      "Environment solved in 353 episodes!\tAverage Score: 1.48\n",
      "\n",
      "Environment solved in 354 episodes!\tAverage Score: 1.44\n",
      "\n",
      "Environment solved in 355 episodes!\tAverage Score: 1.44\n",
      "\n",
      "Environment solved in 356 episodes!\tAverage Score: 1.43\n",
      "\n",
      "Environment solved in 357 episodes!\tAverage Score: 1.43\n",
      "\n",
      "Environment solved in 358 episodes!\tAverage Score: 1.37\n",
      "\n",
      "Environment solved in 359 episodes!\tAverage Score: 1.37\n",
      "Episode 390\tAverage Score: 1.3827\n",
      "77160\n",
      "1254.0748291015625\n",
      "\n",
      "Environment solved in 360 episodes!\tAverage Score: 1.38\n",
      "\n",
      "Environment solved in 361 episodes!\tAverage Score: 1.39\n",
      "\n",
      "Environment solved in 362 episodes!\tAverage Score: 1.31\n",
      "\n",
      "Environment solved in 363 episodes!\tAverage Score: 1.24\n",
      "\n",
      "Environment solved in 364 episodes!\tAverage Score: 1.25\n",
      "\n",
      "Environment solved in 365 episodes!\tAverage Score: 1.24\n",
      "\n",
      "Environment solved in 366 episodes!\tAverage Score: 1.28\n",
      "\n",
      "Environment solved in 367 episodes!\tAverage Score: 1.25\n",
      "\n",
      "Environment solved in 368 episodes!\tAverage Score: 1.28\n",
      "\n",
      "Environment solved in 369 episodes!\tAverage Score: 1.35\n",
      "\n",
      "Environment solved in 370 episodes!\tAverage Score: 1.31\n",
      "\n",
      "Environment solved in 371 episodes!\tAverage Score: 1.30\n",
      "\n",
      "Environment solved in 372 episodes!\tAverage Score: 1.36\n",
      "\n",
      "Environment solved in 373 episodes!\tAverage Score: 1.36\n",
      "\n",
      "Environment solved in 374 episodes!\tAverage Score: 1.36\n",
      "\n",
      "Environment solved in 375 episodes!\tAverage Score: 1.36\n",
      "\n",
      "Environment solved in 376 episodes!\tAverage Score: 1.38\n",
      "\n",
      "Environment solved in 377 episodes!\tAverage Score: 1.33\n",
      "\n",
      "Environment solved in 378 episodes!\tAverage Score: 1.34\n",
      "\n",
      "Environment solved in 379 episodes!\tAverage Score: 1.33\n",
      "\n",
      "Environment solved in 380 episodes!\tAverage Score: 1.33\n",
      "\n",
      "Environment solved in 381 episodes!\tAverage Score: 1.33\n",
      "\n",
      "Environment solved in 382 episodes!\tAverage Score: 1.36\n",
      "\n",
      "Environment solved in 383 episodes!\tAverage Score: 1.40\n",
      "\n",
      "Environment solved in 384 episodes!\tAverage Score: 1.49\n",
      "\n",
      "Environment solved in 385 episodes!\tAverage Score: 1.49\n",
      "\n",
      "Environment solved in 386 episodes!\tAverage Score: 1.50\n",
      "\n",
      "Environment solved in 387 episodes!\tAverage Score: 1.43\n",
      "\n",
      "Environment solved in 388 episodes!\tAverage Score: 1.43\n",
      "\n",
      "Environment solved in 389 episodes!\tAverage Score: 1.47\n",
      "Episode 420\tAverage Score: 1.4460\n",
      "93856\n",
      "3115.88525390625\n",
      "\n",
      "Environment solved in 390 episodes!\tAverage Score: 1.45\n",
      "\n",
      "Environment solved in 391 episodes!\tAverage Score: 1.49\n",
      "\n",
      "Environment solved in 392 episodes!\tAverage Score: 1.50\n",
      "\n",
      "Environment solved in 393 episodes!\tAverage Score: 1.58\n",
      "\n",
      "Environment solved in 394 episodes!\tAverage Score: 1.57\n",
      "\n",
      "Environment solved in 395 episodes!\tAverage Score: 1.50\n",
      "\n",
      "Environment solved in 396 episodes!\tAverage Score: 1.46\n",
      "\n",
      "Environment solved in 397 episodes!\tAverage Score: 1.49\n",
      "\n",
      "Environment solved in 398 episodes!\tAverage Score: 1.45\n",
      "\n",
      "Environment solved in 399 episodes!\tAverage Score: 1.45\n",
      "\n",
      "Environment solved in 400 episodes!\tAverage Score: 1.52\n",
      "\n",
      "Environment solved in 401 episodes!\tAverage Score: 1.52\n",
      "\n",
      "Environment solved in 402 episodes!\tAverage Score: 1.46\n",
      "\n",
      "Environment solved in 403 episodes!\tAverage Score: 1.37\n",
      "\n",
      "Environment solved in 404 episodes!\tAverage Score: 1.39\n",
      "\n",
      "Environment solved in 405 episodes!\tAverage Score: 1.39\n",
      "\n",
      "Environment solved in 406 episodes!\tAverage Score: 1.43\n",
      "\n",
      "Environment solved in 407 episodes!\tAverage Score: 1.47\n",
      "\n",
      "Environment solved in 408 episodes!\tAverage Score: 1.51\n",
      "\n",
      "Environment solved in 409 episodes!\tAverage Score: 1.43\n",
      "\n",
      "Environment solved in 410 episodes!\tAverage Score: 1.43\n",
      "\n",
      "Environment solved in 411 episodes!\tAverage Score: 1.35\n",
      "\n",
      "Environment solved in 412 episodes!\tAverage Score: 1.29\n",
      "\n",
      "Environment solved in 413 episodes!\tAverage Score: 1.21\n",
      "\n",
      "Environment solved in 414 episodes!\tAverage Score: 1.14\n",
      "\n",
      "Environment solved in 415 episodes!\tAverage Score: 1.06\n",
      "\n",
      "Environment solved in 416 episodes!\tAverage Score: 0.98\n",
      "\n",
      "Environment solved in 417 episodes!\tAverage Score: 0.99\n",
      "\n",
      "Environment solved in 418 episodes!\tAverage Score: 0.99\n",
      "\n",
      "Environment solved in 419 episodes!\tAverage Score: 0.94\n",
      "Episode 450\tAverage Score: 0.9450\n",
      "99999\n",
      "4862.01171875\n",
      "\n",
      "Environment solved in 420 episodes!\tAverage Score: 0.95\n",
      "\n",
      "Environment solved in 421 episodes!\tAverage Score: 0.88\n",
      "\n",
      "Environment solved in 422 episodes!\tAverage Score: 0.86\n",
      "\n",
      "Environment solved in 423 episodes!\tAverage Score: 0.80\n",
      "\n",
      "Environment solved in 424 episodes!\tAverage Score: 0.80\n",
      "\n",
      "Environment solved in 425 episodes!\tAverage Score: 0.81\n",
      "\n",
      "Environment solved in 426 episodes!\tAverage Score: 0.83\n",
      "\n",
      "Environment solved in 427 episodes!\tAverage Score: 0.79\n",
      "\n",
      "Environment solved in 428 episodes!\tAverage Score: 0.75\n",
      "\n",
      "Environment solved in 429 episodes!\tAverage Score: 0.71\n",
      "\n",
      "Environment solved in 430 episodes!\tAverage Score: 0.68\n",
      "\n",
      "Environment solved in 431 episodes!\tAverage Score: 0.68\n",
      "\n",
      "Environment solved in 432 episodes!\tAverage Score: 0.66\n",
      "\n",
      "Environment solved in 433 episodes!\tAverage Score: 0.69\n",
      "\n",
      "Environment solved in 434 episodes!\tAverage Score: 0.67\n",
      "\n",
      "Environment solved in 435 episodes!\tAverage Score: 0.73\n",
      "\n",
      "Environment solved in 436 episodes!\tAverage Score: 0.68\n",
      "\n",
      "Environment solved in 437 episodes!\tAverage Score: 0.64\n",
      "\n",
      "Environment solved in 438 episodes!\tAverage Score: 0.60\n",
      "\n",
      "Environment solved in 439 episodes!\tAverage Score: 0.67\n",
      "\n",
      "Environment solved in 440 episodes!\tAverage Score: 0.67\n",
      "\n",
      "Environment solved in 441 episodes!\tAverage Score: 0.71\n",
      "\n",
      "Environment solved in 442 episodes!\tAverage Score: 0.71\n",
      "\n",
      "Environment solved in 443 episodes!\tAverage Score: 0.79\n",
      "\n",
      "Environment solved in 444 episodes!\tAverage Score: 0.84\n",
      "\n",
      "Environment solved in 445 episodes!\tAverage Score: 0.87\n",
      "\n",
      "Environment solved in 446 episodes!\tAverage Score: 0.88\n",
      "\n",
      "Environment solved in 447 episodes!\tAverage Score: 0.94\n",
      "\n",
      "Environment solved in 448 episodes!\tAverage Score: 1.03\n",
      "\n",
      "Environment solved in 449 episodes!\tAverage Score: 1.12\n",
      "Episode 480\tAverage Score: 1.1620\n",
      "99999\n",
      "8265.3447265625\n",
      "\n",
      "Environment solved in 450 episodes!\tAverage Score: 1.16\n",
      "\n",
      "Environment solved in 451 episodes!\tAverage Score: 1.24\n",
      "\n",
      "Environment solved in 452 episodes!\tAverage Score: 1.33\n",
      "\n",
      "Environment solved in 453 episodes!\tAverage Score: 1.39\n",
      "\n",
      "Environment solved in 454 episodes!\tAverage Score: 1.48\n",
      "\n",
      "Environment solved in 455 episodes!\tAverage Score: 1.54\n",
      "\n",
      "Environment solved in 456 episodes!\tAverage Score: 1.52\n",
      "\n",
      "Environment solved in 457 episodes!\tAverage Score: 1.56\n",
      "\n",
      "Environment solved in 458 episodes!\tAverage Score: 1.55\n",
      "\n",
      "Environment solved in 459 episodes!\tAverage Score: 1.50\n",
      "\n",
      "Environment solved in 460 episodes!\tAverage Score: 1.53\n",
      "\n",
      "Environment solved in 461 episodes!\tAverage Score: 1.50\n",
      "\n",
      "Environment solved in 462 episodes!\tAverage Score: 1.53\n",
      "\n",
      "Environment solved in 463 episodes!\tAverage Score: 1.59\n",
      "\n",
      "Environment solved in 464 episodes!\tAverage Score: 1.64\n",
      "\n",
      "Environment solved in 465 episodes!\tAverage Score: 1.65\n",
      "\n",
      "Environment solved in 466 episodes!\tAverage Score: 1.66\n",
      "\n",
      "Environment solved in 467 episodes!\tAverage Score: 1.62\n",
      "\n",
      "Environment solved in 468 episodes!\tAverage Score: 1.70\n",
      "\n",
      "Environment solved in 469 episodes!\tAverage Score: 1.66\n",
      "\n",
      "Environment solved in 470 episodes!\tAverage Score: 1.67\n",
      "score\n",
      "2.7000000402331352\n",
      "N_Bootstrap\n",
      "4\n",
      "seed\n",
      "1\n",
      "prio\n",
      "0.8\n",
      "Episode 0\tAverage Score: 0.0000\n",
      "15\n",
      "0.05539489334821701\n",
      "Episode 30\tAverage Score: 0.0000\n",
      "441\n",
      "0.019368959426879884\n",
      "Episode 60\tAverage Score: 0.0000\n",
      "867\n",
      "0.008931854739785194\n",
      "Episode 90\tAverage Score: 0.0000\n",
      "1294\n",
      "0.009054789155721665\n",
      "Episode 120\tAverage Score: 0.0000\n",
      "1723\n",
      "0.007068060174584389\n",
      "Episode 150\tAverage Score: 0.0030\n",
      "2167\n",
      "0.024040786549448967\n",
      "Episode 180\tAverage Score: 0.0000\n",
      "2596\n",
      "0.05198980122804642\n",
      "Episode 210\tAverage Score: 0.0100\n",
      "3103\n",
      "0.06517666578292847\n",
      "Episode 240\tAverage Score: 0.0100\n",
      "3627\n",
      "0.04549138620495796\n",
      "Episode 270\tAverage Score: 0.0167\n",
      "4219\n",
      "0.050967875868082047\n",
      "Episode 300\tAverage Score: 0.0287\n",
      "4874\n",
      "0.05946063622832298\n",
      "Episode 330\tAverage Score: 0.0263\n",
      "5532\n",
      "0.05623432993888855\n",
      "Episode 360\tAverage Score: 0.0287\n",
      "6139\n",
      "0.062462594360113144\n",
      "Episode 390\tAverage Score: 0.0393\n",
      "6928\n",
      "0.0586150623857975\n",
      "Episode 420\tAverage Score: 0.0463\n",
      "7772\n",
      "0.05200866982340813\n",
      "Episode 450\tAverage Score: 0.0433\n",
      "8572\n",
      "0.05598475784063339\n",
      "Episode 480\tAverage Score: 0.0567\n",
      "9548\n",
      "0.0653856098651886\n",
      "score\n",
      "0.10000000149011612\n",
      "N_Bootstrap\n",
      "4\n",
      "seed\n",
      "2\n",
      "prio\n",
      "0.8\n",
      "Episode 0\tAverage Score: 0.0000\n",
      "14\n",
      "0.06169348007440567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 30\tAverage Score: 0.0000\n",
      "440\n",
      "0.003547871485352516\n",
      "Episode 60\tAverage Score: 0.0000\n",
      "866\n",
      "0.004496711306273937\n",
      "Episode 90\tAverage Score: 0.0000\n",
      "1292\n",
      "0.003551917150616646\n",
      "Episode 120\tAverage Score: 0.0000\n",
      "1718\n",
      "0.005648745991289616\n",
      "Episode 150\tAverage Score: 0.0000\n",
      "2144\n",
      "0.005767921753227711\n",
      "Episode 180\tAverage Score: 0.0000\n",
      "2570\n",
      "0.0046691902205348015\n",
      "Episode 210\tAverage Score: 0.0000\n",
      "2996\n",
      "0.005853245802223682\n",
      "Episode 240\tAverage Score: 0.0000\n",
      "3422\n",
      "0.003278113901615143\n",
      "Episode 270\tAverage Score: 0.0000\n",
      "3848\n",
      "0.00607296621799469\n",
      "Episode 300\tAverage Score: 0.0000\n",
      "4274\n",
      "0.003586212173104286\n",
      "Episode 330\tAverage Score: 0.0000\n",
      "4700\n",
      "0.004740922711789608\n",
      "Episode 360\tAverage Score: 0.0000\n",
      "5126\n",
      "0.0030097467824816704\n",
      "Episode 390\tAverage Score: 0.0000\n",
      "5552\n",
      "0.0034759845584630966\n",
      "Episode 420\tAverage Score: 0.0000\n",
      "5978\n",
      "0.006100426264107227\n",
      "Episode 450\tAverage Score: 0.0000\n",
      "6404\n",
      "0.006503004416823387\n",
      "Episode 480\tAverage Score: 0.0000\n",
      "6830\n",
      "0.006455112084746361\n",
      "score\n",
      "0.0\n",
      "N_Bootstrap\n",
      "4\n",
      "seed\n",
      "0\n",
      "prio\n",
      "0.0\n",
      "Episode 0\tAverage Score: 0.0000\n",
      "15\n",
      "0.06017991325259209\n",
      "Episode 30\tAverage Score: 0.0030\n",
      "457\n",
      "0.021582579240202904\n",
      "Episode 60\tAverage Score: 0.0247\n",
      "1016\n",
      "0.0373975895345211\n",
      "Episode 90\tAverage Score: 0.0250\n",
      "1587\n",
      "0.10535336285829544\n",
      "Episode 120\tAverage Score: 0.0803\n",
      "2570\n",
      "0.10801460593938828\n",
      "Episode 150\tAverage Score: 0.0943\n",
      "3570\n",
      "0.14983354306221008\n",
      "Episode 180\tAverage Score: 0.2167\n",
      "6270\n",
      "0.36317188835144043\n",
      "Episode 210\tAverage Score: 0.1233\n",
      "7955\n",
      "0.2832261323928833\n",
      "Episode 240\tAverage Score: 0.2363\n",
      "11013\n",
      "0.7680386304855347\n",
      "Episode 270\tAverage Score: 0.2900\n",
      "14699\n",
      "1.147188663482666\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bd90dd2285ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0magents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLearning_Rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_Bootstrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR_actor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR_critic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprio_epsilon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_agents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mall_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddpg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_Bootstrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mscore_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-bd90dd2285ac>\u001b[0m in \u001b[0;36mddpg\u001b[0;34m(env, agents, print_every, n_episodes, max_t, Batch_size, N_Bootstrap, seed)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_agents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Machine_Learning/reinforcement_learning/deep-reinforcement-learning/p3_collab-compet/ddpg_agent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_bootstrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Machine_Learning/reinforcement_learning/deep-reinforcement-learning/p3_collab-compet/prioritized_memory.py\u001b[0m in \u001b[0;36msample_bootstrap\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mnext_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_state\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mdones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \"\"\"\n\u001b[1;32m    282\u001b[0m     \u001b[0m_warn_for_nonsequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \"\"\"\n\u001b[1;32m    282\u001b[0m     \u001b[0m_warn_for_nonsequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36matleast_2d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     \"\"\"\n\u001b[0;32m--> 591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0m__array_priority__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m    \u001b[0;31m# prefer Tensor ops over numpy ones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Parallel Training ####\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "env = UnityEnvironment(file_name=\"Tennis_Linux/Tennis.x86_64\")#, no_graphics = True)\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from ddpg_agent import Agent\n",
    "from collections import deque\n",
    "\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "states = env_info.vector_observations\n",
    "action_size = brain.vector_action_space_size\n",
    "state_size = states.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "print_every = 30\n",
    "n_episodes= 500 #4000 # 2000\n",
    "max_t=1000\n",
    "Batch_size = 128# 512\n",
    "N_Bootstrap = 4  ## New\n",
    "Learning_Rate = 4 #10\n",
    "seed = 0\n",
    "\n",
    "LR_actor = 1e-3  #4        # learning rate of the actor \n",
    "LR_critic = 1e-3        # learning rate of the critic\n",
    "gamma = 0.99#0.99            # discount factor\n",
    "\n",
    "#priorized replay\n",
    "prio_epsilon = 0.001\n",
    "prio_beta = .8\n",
    "prio_exponent = .8\n",
    "\n",
    "# noise\n",
    "theta = .03\n",
    "sigma = .04\n",
    "def ddpg(env, agents, print_every, n_episodes, max_t, Batch_size, N_Bootstrap, seed):\n",
    "    scores_deque = deque(maxlen=print_every)\n",
    "    all_scores = []\n",
    "    for i_episode in range(0, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        for agent in agents:\n",
    "            agent.reset()\n",
    "        states = env_info.vector_observations\n",
    "        scores = np.asarray([0.,0.])\n",
    "        reduction = 2. #((n_episodes-i_episode+0.0)/(n_episodes+0.0))**3.\n",
    "        noise_down = 0.9999\n",
    "        for t in range(max_t):\n",
    "            reduction *= noise_down\n",
    "            actions = [agents[i].act(states[i],reduction) for i in range(num_agents)]\n",
    "            env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "            next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "            rewards = env_info.rewards                         # get reward (for each agent)\n",
    "            dones = env_info.local_done                        # see if episode finished\n",
    "            scores += np.asarray(env_info.rewards)\n",
    "            for i in range(num_agents):\n",
    "                agents[i].step(states[i], actions[i], rewards[i], next_states[i], dones[i])\n",
    "            states = next_states\n",
    "            if np.any(dones):\n",
    "                break\n",
    "        avg_score = np.max(scores) \n",
    "        #print (scores)\n",
    "        scores_deque.append(avg_score)\n",
    "        all_scores.append(avg_score)\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.4f}'.format(i_episode, np.mean(scores_deque)))\n",
    "            print (len(agent.memory.prios))\n",
    "            print (max(agent.memory.prios))\n",
    "        if np.mean(scores_deque)>=0.5:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-print_every, np.mean(scores_deque)))\n",
    "            torch.save(agents[0].actor_local.state_dict(), 'checkpoint_actor_agent0'+str(seed)+ \"_\" + str(N_Bootstrap) +\"_\"+ str(prio)+\".pth\")\n",
    "            torch.save(agents[0].critic_local.state_dict(), 'checkpoint_critic_agent0'+str(seed)+ \"_\" + str(N_Bootstrap) +\"_\"+ str(prio)+\".pth\")\n",
    "            torch.save(agents[1].actor_local.state_dict(), 'checkpoint_actor_agent1'+str(seed)+ \"_\" + str(N_Bootstrap) +\"_\"+ str(prio)+\".pth\")\n",
    "            torch.save(agents[1].critic_local.state_dict(), 'checkpoint_critic_agent1'+str(seed)+ \"_\" + str(N_Bootstrap) +\"_\"+ str(prio)+\".pth\")\n",
    "            \n",
    "    return all_scores\n",
    "score_table = []\n",
    "for N_Bootstrap in [4,1]:\n",
    "    for prio in [0.8,0.]:\n",
    "        for seed in range(3):\n",
    "            print (\"N_Bootstrap\")\n",
    "            print (N_Bootstrap)\n",
    "            print (\"seed\")\n",
    "            print (seed)\n",
    "            print (\"prio\")\n",
    "            print (prio)\n",
    "            agents = [Agent(state_size, action_size, seed, Batch_size, Learning_Rate, N_Bootstrap, LR_actor, LR_critic, gamma, theta, sigma, prio, prio, prio_epsilon) for _ in range(num_agents)]\n",
    "            all_scores = ddpg(env, agents, print_every, n_episodes, max_t, Batch_size, N_Bootstrap, seed)\n",
    "            score_table.append(all_scores)\n",
    "            print (\"score\")\n",
    "            print (max(all_scores))\n",
    "            torch.save(agents[0].actor_local.state_dict(), 'checkpoint_actor_agent0'+str(seed)+ \"_\" + str(N_Bootstrap) +\"_\"+ str(prio)+\".pth\")\n",
    "            torch.save(agents[0].critic_local.state_dict(), 'checkpoint_critic_agent0'+str(seed)+ \"_\" + str(N_Bootstrap) +\"_\"+ str(prio)+\".pth\")\n",
    "            torch.save(agents[1].actor_local.state_dict(), 'checkpoint_actor_agent1'+str(seed)+ \"_\" + str(N_Bootstrap) +\"_\"+ str(prio)+\".pth\")\n",
    "            torch.save(agents[1].critic_local.state_dict(), 'checkpoint_critic_agent1'+str(seed)+ \"_\" + str(N_Bootstrap) +\"_\"+ str(prio)+\".pth\")\n",
    "                        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "num = 50\n",
    "average_line = [np.mean(np.asarray(score_table[0])[index-num:index+num]) for index in np.arange(num,len(score_table[0])-num)]\n",
    "plt.plot(score_table[0], color = \"lightgray\")\n",
    "plt.axhline(y=0.5)\n",
    "plt.plot(np.arange(num, len(score_table[0])-num,1), average_line, color = \"orange\")\n",
    "plt.xlabel(\"episodes\", fontsize = 14)\n",
    "plt.ylabel(\"max. reward\", fontsize = 14)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.savefig(\"Result.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_line = [np.mean(np.asarray(score_table[0])[index-num:index+num]) for index in np.arange(num,len(score_table[0])-num)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = agents[0]\n",
    "a = np.vstack([e.reward for e in agent.memory.memory if e is not None])\n",
    "b = agent.memory.prios\n",
    "#any(a)>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009697718545794487\n",
      "0.013772689165943796\n",
      "0.0075096900659513705\n"
     ]
    }
   ],
   "source": [
    "print (np.mean(np.asarray(b)[[np.where(a>0)][0][0]]))\n",
    "print (np.mean(np.asarray(b)[[np.where(a<0)][0][0]]))\n",
    "print (np.mean(np.asarray(b)[[np.where(a==0)][0][0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
